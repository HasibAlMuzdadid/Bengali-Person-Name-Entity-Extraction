{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13354282,"sourceType":"datasetVersion","datasetId":8469980}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade transformers==4.43.3 huggingface_hub==0.24.6 --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T23:37:11.245201Z","iopub.execute_input":"2025-10-14T23:37:11.245482Z","iopub.status.idle":"2025-10-14T23:37:14.737863Z","shell.execute_reply.started":"2025-10-14T23:37:11.245461Z","shell.execute_reply":"2025-10-14T23:37:14.736754Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"!pip install bnlp_toolkit --quiet\n!pip install git+https://github.com/csebuetnlp/normalizer --quiet","metadata":{"_cell_guid":"5b1e876e-5039-4f67-81fe-13e4209da39d","_uuid":"9d3c0e88-4279-4bbf-a0cf-a0a477346126","execution":{"iopub.status.busy":"2025-10-14T22:26:23.539075Z","iopub.execute_input":"2025-10-14T22:26:23.539378Z","iopub.status.idle":"2025-10-14T22:26:34.043788Z","shell.execute_reply.started":"2025-10-14T22:26:23.539354Z","shell.execute_reply":"2025-10-14T22:26:34.043053Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nnormalizer 0.0.1 requires emoji==1.4.2, but you have emoji 1.7.0 which is incompatible.\nnormalizer 0.0.1 requires ftfy==6.0.3, but you have ftfy 6.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbnlp-toolkit 4.0.3 requires emoji==1.7.0, but you have emoji 1.4.2 which is incompatible.\nbnlp-toolkit 4.0.3 requires ftfy==6.2.0, but you have ftfy 6.0.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import transformers\nimport huggingface_hub\n\nprint(\"Transformers version:\", transformers.__version__)\nprint(\"Hugging Face Hub version:\", huggingface_hub.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T22:26:37.051004Z","iopub.execute_input":"2025-10-14T22:26:37.051312Z","iopub.status.idle":"2025-10-14T22:26:40.006424Z","shell.execute_reply.started":"2025-10-14T22:26:37.051285Z","shell.execute_reply":"2025-10-14T22:26:40.005702Z"}},"outputs":[{"name":"stdout","text":"Transformers version: 4.43.3\nHugging Face Hub version: 0.24.6\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install evaluate seqeval --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T22:26:44.048537Z","iopub.execute_input":"2025-10-14T22:26:44.049187Z","iopub.status.idle":"2025-10-14T22:26:47.356745Z","shell.execute_reply.started":"2025-10-14T22:26:44.049161Z","shell.execute_reply":"2025-10-14T22:26:47.355563Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# !rm -rf seqeval evaluate metrics __pycache__","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pyarrow, datasets, evaluate, transformers, seqeval\nprint(f\"pyarrow: {pyarrow.__version__}\")\nprint(f\"datasets: {datasets.__version__}\")\nprint(f\"evaluate: {evaluate.__version__}\")\nprint(f\"transformers: {transformers.__version__}\")\nimport importlib.metadata\nprint(f\"seqeval: {importlib.metadata.version('seqeval')}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T22:26:51.160341Z","iopub.execute_input":"2025-10-14T22:26:51.160671Z","iopub.status.idle":"2025-10-14T22:26:58.758342Z","shell.execute_reply.started":"2025-10-14T22:26:51.160644Z","shell.execute_reply":"2025-10-14T22:26:58.757609Z"}},"outputs":[{"name":"stderr","text":"2025-10-14 22:26:54.056781: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760480814.083652  153330 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760480814.091551  153330 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"pyarrow: 21.0.0\ndatasets: 4.1.1\nevaluate: 0.4.6\ntransformers: 4.43.3\nseqeval: 1.2.2\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"seqeval\")\nprint(\"Seqeval metric loaded successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T22:27:04.054261Z","iopub.execute_input":"2025-10-14T22:27:04.055149Z","iopub.status.idle":"2025-10-14T22:27:05.450035Z","shell.execute_reply.started":"2025-10-14T22:27:04.055121Z","shell.execute_reply":"2025-10-14T22:27:05.449110Z"}},"outputs":[{"name":"stdout","text":"Seqeval metric loaded successfully\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import StratifiedKFold\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import  DataLoader, Dataset\nfrom torch.optim import AdamW\n\nimport transformers \nfrom transformers import AutoModel, AutoConfig, AutoTokenizer\n%env TOKENIZERS_PARALLELISM=true\n\nfrom bnlp import BasicTokenizer\nfrom normalizer import normalize\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"_cell_guid":"5b1e876e-5039-4f67-81fe-13e4209da39d","_uuid":"9d3c0e88-4279-4bbf-a0cf-a0a477346126","collapsed":false,"execution":{"iopub.status.busy":"2025-10-14T22:27:07.480155Z","iopub.execute_input":"2025-10-14T22:27:07.480450Z","iopub.status.idle":"2025-10-14T22:27:26.122225Z","shell.execute_reply.started":"2025-10-14T22:27:07.480428Z","shell.execute_reply":"2025-10-14T22:27:26.121632Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","text":"env: TOKENIZERS_PARALLELISM=true\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def process_label(label):    \n    name_label=[\"B-PER\", \"I-PER\"]\n    new_name_label= [\"B-NAME\", \"I-NAME\"]\n    labellist= []\n    for i in label:\n        if i in name_label:\n            labellist.append(new_name_label[name_label.index(i)])\n        else:\n            labellist.append('O')      \n    return labellist\n\n\n\ndef readfile(filename):\n    file = open(filename, encoding=\"utf-8\")\n    sentences = []\n    sentence = []\n    labels= []\n    label= []\n    for line in file:\n        if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\" or line[1]==\"\\n\":\n            if len(sentence) > 0:\n                sentence= \" \".join(sentence)\n                sentences.append(sentence)\n                labels.append(label)\n                sentence = []\n                label= []\n            continue\n        \n        splits = line.split('\\t')\n        if (splits[-1]=='\\n'):\n            continue\n        sentence.append(splits[0])\n        label.append(splits[-1].split(\"\\n\")[0]) # remove extra \"\\n\"\n\n    if len(sentence) >0: # for last sentence\n        sentence= \" \".join(sentence)\n        sentences.append(sentence)\n        labels.append(label)\n        sentence = []\n        label= []\n    \n    file.close()\n\n    df= pd.DataFrame(columns=[\"sentences\", \"labels\"])\n    df['sentences']= sentences\n    df['labels']= labels\n    df['labels']= df['labels'].apply(lambda x: process_label(x))\n    df['sentences']= df['sentences'].apply(lambda x: normalize(x))\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:27:30.131443Z","iopub.execute_input":"2025-10-14T22:27:30.132062Z","iopub.status.idle":"2025-10-14T22:27:30.139412Z","shell.execute_reply.started":"2025-10-14T22:27:30.132038Z","shell.execute_reply":"2025-10-14T22:27:30.138648Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_data_path = \"/kaggle/input/bengali-name-recognition/dataset/train_data.txt\"\ntest_data_path = \"/kaggle/input/bengali-name-recognition/dataset/test_data.txt\"","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:27:34.568563Z","iopub.execute_input":"2025-10-14T22:27:34.569307Z","iopub.status.idle":"2025-10-14T22:27:34.573462Z","shell.execute_reply.started":"2025-10-14T22:27:34.569281Z","shell.execute_reply":"2025-10-14T22:27:34.572270Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_dataset = readfile(train_data_path)\ntest_dataset = readfile(test_data_path)","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:27:36.942426Z","iopub.execute_input":"2025-10-14T22:27:36.942954Z","iopub.status.idle":"2025-10-14T22:27:38.268566Z","shell.execute_reply.started":"2025-10-14T22:27:36.942927Z","shell.execute_reply":"2025-10-14T22:27:38.267705Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(train_dataset.shape, test_dataset.shape)\ntrain_dataset.head(), test_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:27:40.131733Z","iopub.execute_input":"2025-10-14T22:27:40.132488Z","iopub.status.idle":"2025-10-14T22:27:40.144046Z","shell.execute_reply.started":"2025-10-14T22:27:40.132466Z","shell.execute_reply":"2025-10-14T22:27:40.143280Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(4612, 2) (1950, 2)\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(                                           sentences  \\\n 0  কী কারণে তাঁদের মধ্যে ঝামেলা হয়েছে , তা জানি ...   \n 1  আশঙ্কাজনক অবস্থায় উপজেলা স্বাস্থ্য কমপ্লেক্সে...   \n 2  খুলনার দিঘলিয়া উপজেলার বারাকপুর মধ্যপাড়ায় গ...   \n 3  পুলিশের পিটুনিতে কেসমত আলীর মৃত্যু হয়েছে বলে ...   \n 4  তবে পুলিশ বলছে , ওই ব্যক্তি পুলিশ দেখে পড়ে গে...   \n \n                                               labels  \n 0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n 1                  [O, O, O, O, O, O, O, O, O, O, O]  \n 2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n 3        [O, O, B-NAME, I-NAME, O, O, O, O, O, O, O]  \n 4         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]  ,\n                                            sentences  \\\n 0  উন্নয়নের বিস্ময় বাংলাদেশ বাংলাদেশের অগ্রগতি ...   \n 1  অর্থনীতি ও আর্থসামাজিক বেশির ভাগ সূচকে বাংলাদে...   \n 2    নিম্ন আয়ের দেশগুলোকে ছাড়িয়েছে তো অনেক আগেই ।   \n 3  আন্তর্জাতিক মুদ্রা তহবিল ( আইএমএফ ) গত সপ্তাহে...   \n 4  সবাইকে অন্তর্ভুক্ত করে প্রবৃদ্ধি অর্জনের ক্ষেত...   \n \n                                               labels  \n 0                        [O, O, O, O, O, O, O, O, O]  \n 1               [O, O, O, O, O, O, O, O, O, O, O, O]  \n 2                           [O, O, O, O, O, O, O, O]  \n 3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n 4         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]  )"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def check_common_entry(df1, df2):\n    b_tokenizer= BasicTokenizer()\n    list1= [tuple(b_tokenizer.tokenize(txt)) for txt in df1['sentences']]\n    list2= [tuple(b_tokenizer.tokenize(txt)) for txt in df2['sentences']]\n    common= set(list1).intersection(set(list2))\n    return common\n\n\ndef remove_common_entries(df, common):\n    b_tokenizer= BasicTokenizer()\n    # Pre-tokenize all df sentences\n    df_tokens = df['sentences'].apply(lambda x: tuple(b_tokenizer.tokenize(x)))\n    # Convert common to set for fast lookup\n    common_set = set(common)\n    # Mask for rows to keep (sentence tokens not in common_set)\n    mask = df_tokens.apply(lambda x: x not in common_set)\n    df_filtered = df[mask].reset_index(drop=True)\n    \n    removed_count = len(df) - len(df_filtered)\n    print(f\"Total {removed_count} rows removed from the dataset.\")\n    return df_filtered\n\n\ndef remove_erroneous_entries(df):\n    temp_df= df.copy()\n    b_tokenizer= BasicTokenizer()\n    temp_df['len_labels']= temp_df['labels'].apply(lambda x: len(x))\n    temp_df['len_words']= temp_df['sentences'].apply(lambda x: len(b_tokenizer.tokenize(x)))\n    \n    error_=[]\n    for i in range(len(temp_df)):\n        if temp_df['len_labels'][i] != temp_df['len_words'][i]:\n            error_.append(i)\n    print(f\"{len(error_)} no of data was detected as erroneous and discarded.\")\n    df= df.drop(error_).reset_index(drop= True)\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:27:44.709243Z","iopub.execute_input":"2025-10-14T22:27:44.709786Z","iopub.status.idle":"2025-10-14T22:27:44.716747Z","shell.execute_reply.started":"2025-10-14T22:27:44.709763Z","shell.execute_reply":"2025-10-14T22:27:44.715934Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"common= check_common_entry(train_dataset, test_dataset) \nprint(f\"No of common sentences between Train and Test dataset: {len(common)}\")","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:27:48.398703Z","iopub.execute_input":"2025-10-14T22:27:48.399260Z","iopub.status.idle":"2025-10-14T22:27:48.705906Z","shell.execute_reply.started":"2025-10-14T22:27:48.399239Z","shell.execute_reply":"2025-10-14T22:27:48.705061Z"},"trusted":true},"outputs":[{"name":"stdout","text":"No of common sentences between Train and Test dataset: 81\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"test_dataset_= remove_common_entries(test_dataset, common)\nprint(test_dataset.shape, test_dataset_.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T22:27:51.156384Z","iopub.execute_input":"2025-10-14T22:27:51.156693Z","iopub.status.idle":"2025-10-14T22:27:51.254266Z","shell.execute_reply.started":"2025-10-14T22:27:51.156672Z","shell.execute_reply":"2025-10-14T22:27:51.253559Z"}},"outputs":[{"name":"stdout","text":"Total 92 rows removed from the dataset.\n(1950, 2) (1858, 2)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"train_data = remove_erroneous_entries(train_dataset)\ntest_data = remove_erroneous_entries(test_dataset_)\n\nprint([train_dataset.shape,train_data.shape], [test_dataset_.shape,test_data.shape])","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:27:56.026432Z","iopub.execute_input":"2025-10-14T22:27:56.026731Z","iopub.status.idle":"2025-10-14T22:27:56.363723Z","shell.execute_reply.started":"2025-10-14T22:27:56.026708Z","shell.execute_reply":"2025-10-14T22:27:56.363059Z"},"trusted":true},"outputs":[{"name":"stdout","text":"995 no of data was detected as erroneous and discarded.\n417 no of data was detected as erroneous and discarded.\n[(4612, 2), (3617, 2)] [(1858, 2), (1441, 2)]\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"train_data['name_tag']= train_data['labels'].apply(lambda x: 1 if x.count(\"B-NAME\")>0 else 0)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:28:00.034959Z","iopub.execute_input":"2025-10-14T22:28:00.035251Z","iopub.status.idle":"2025-10-14T22:28:00.048741Z","shell.execute_reply.started":"2025-10-14T22:28:00.035230Z","shell.execute_reply":"2025-10-14T22:28:00.047966Z"},"trusted":true},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                           sentences  \\\n0  আশঙ্কাজনক অবস্থায় উপজেলা স্বাস্থ্য কমপ্লেক্সে...   \n1  খুলনার দিঘলিয়া উপজেলার বারাকপুর মধ্যপাড়ায় গ...   \n2  পুলিশের পিটুনিতে কেসমত আলীর মৃত্যু হয়েছে বলে ...   \n3  তবে পুলিশ বলছে , ওই ব্যক্তি পুলিশ দেখে পড়ে গে...   \n4  কেসমতের পরিবার , এলাকাবাসী ও পুলিশ সূত্রে জানা...   \n\n                                              labels  name_tag  \n0                  [O, O, O, O, O, O, O, O, O, O, O]         0  \n1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...         1  \n2        [O, O, B-NAME, I-NAME, O, O, O, O, O, O, O]         1  \n3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]         0  \n4  [B-NAME, O, O, O, O, O, O, O, O, O, O, O, O, O...         1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentences</th>\n      <th>labels</th>\n      <th>name_tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>আশঙ্কাজনক অবস্থায় উপজেলা স্বাস্থ্য কমপ্লেক্সে...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>খুলনার দিঘলিয়া উপজেলার বারাকপুর মধ্যপাড়ায় গ...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>পুলিশের পিটুনিতে কেসমত আলীর মৃত্যু হয়েছে বলে ...</td>\n      <td>[O, O, B-NAME, I-NAME, O, O, O, O, O, O, O]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>তবে পুলিশ বলছে , ওই ব্যক্তি পুলিশ দেখে পড়ে গে...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>কেসমতের পরিবার , এলাকাবাসী ও পুলিশ সূত্রে জানা...</td>\n      <td>[B-NAME, O, O, O, O, O, O, O, O, O, O, O, O, O...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"print(f\"With name token: {sum(train_data['name_tag'])}\")\nprint(f\"Without name token: {len(train_data)-sum(train_data['name_tag'])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T22:28:03.129654Z","iopub.execute_input":"2025-10-14T22:28:03.130253Z","iopub.status.idle":"2025-10-14T22:28:03.135302Z","shell.execute_reply.started":"2025-10-14T22:28:03.130227Z","shell.execute_reply":"2025-10-14T22:28:03.134376Z"}},"outputs":[{"name":"stdout","text":"With name token: 826\nWithout name token: 2791\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# test_data['name_tag']= test_data['labels'].apply(lambda x: 1 if x.count(\"B-NAME\")>0 else 0)\n# test_data.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(f\"With name token: {sum(test_data['name_tag'])}\")\n# print(f\"Without name token: {len(test_data)-sum(test_data['name_tag'])}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def downsampling(df):\n    random.seed(42)\n    index_0= df[df['name_tag']==0].index   #indexes without name entity\n    index_1= df[df['name_tag']==1].index   #indexes with name entity\n    index_n= None\n    if len(index_0) > len(index_1):\n        index = [i for i in index_0]\n        index_n= random.sample(index, k= len(index_0) - len(index_1))\n    if index_n is not None:\n        df= df.drop(index_n).reset_index(drop= True)\n    return df\n\n\ndef upsampling(df, upsample_size=1.0):\n    random.seed(42)\n    df['name_tag'] = df['labels'].apply(lambda x: 1 if x.count(\"B-NAME\") > 0 else 0)\n    index_0 = df[df['name_tag'] == 0].index\n    index_1 = df[df['name_tag'] == 1].index\n\n    if len(index_0) > len(index_1):\n        n_diff = len(index_0) - len(index_1)\n        k = int(n_diff * upsample_size)\n        index_add = random.choices(index_1, k=k)\n    elif len(index_1) > len(index_0):\n        n_diff = len(index_1) - len(index_0)\n        k = int(n_diff * upsample_size)\n        index_add = random.choices(index_0, k=k)\n    else:\n        index_add = []\n\n    if index_add:\n        df = pd.concat([df, df.loc[index_add]]).reset_index(drop=True)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2025-10-14T23:36:43.365407Z","iopub.execute_input":"2025-10-14T23:36:43.365792Z","iopub.status.idle":"2025-10-14T23:36:43.372893Z","shell.execute_reply.started":"2025-10-14T23:36:43.365770Z","shell.execute_reply":"2025-10-14T23:36:43.372256Z"},"trusted":true},"outputs":[],"execution_count":51},{"cell_type":"code","source":"class CONFIG:\n    train= True \n    debug= False \n    seed= 42\n    n_folds= 3\n    num_epochs= 50\n    label_names=['O', 'B-NAME', 'I-NAME']\n    num_labels= len(label_names)\n    model_name= \"celloscopeai/celloscope-28000-ner-banglabert-finetuned\"  #\"csebuetnlp/banglabert\"  #\"csebuetnlp/banglabert_large\" \n    model_checkpoint= \"/kaggle/working/best_model_0.bin\"\n    max_length= 126\n    \n    do_normalize= True\n    do_downsampling= False\n    do_upsampling= False\n    upsample_size= 1\n    train_batch_size= 8\n    valid_batch_size= 16\n    test_batch_size= 16\n    num_workers= 2\n    device= torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    \n    gradient_accumulation_steps= 1\n    learning_rate= 2e-5\n    weight_decay= 1e-2\n    scheduler= \"CosineAnnealingWarmRestarts\" #\"CosineAnnealingLR\" #\"linear\"\n    T_max= 500\n    T_0= 500\n    min_lr= 1e-7\n    \n    eps = 1e-6\n    betas= [0.9, 0.999]\n    \nif CONFIG.debug:\n    CONFIG.n_folds= 2\n    CONFIG.num_epochs=2\n    CONFIG.dataset_size= 300","metadata":{"execution":{"iopub.status.busy":"2025-10-14T23:36:27.965256Z","iopub.execute_input":"2025-10-14T23:36:27.965754Z","iopub.status.idle":"2025-10-14T23:36:27.971549Z","shell.execute_reply.started":"2025-10-14T23:36:27.965733Z","shell.execute_reply":"2025-10-14T23:36:27.970641Z"},"trusted":true},"outputs":[],"execution_count":50},{"cell_type":"code","source":"# remove_erroneous_entries(test_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if CONFIG.do_upsampling:\n    # up_dataset= upsampling(train_data, upsample_size= CONFIG.upsample_size)\n    dataset= upsampling(train_data, upsample_size= CONFIG.upsample_size)\nif CONFIG.do_downsampling:\n    # down_dataset= downsampling(train_data)\n    dataset= downsampling(train_data)\n\n# dataset=train_data.copy()","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:28:21.661088Z","iopub.execute_input":"2025-10-14T22:28:21.661347Z","iopub.status.idle":"2025-10-14T22:28:21.673242Z","shell.execute_reply.started":"2025-10-14T22:28:21.661329Z","shell.execute_reply":"2025-10-14T22:28:21.672387Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"print(f\"Dataset shape: \\nupsampled: {up_dataset.shape}, downsampled: {down_dataset.shape}, original train: {train_dataset.shape}\")\n\nprint(\"\\n.......upsampled data.......\")\nprint(f\"With name token : {sum(up_dataset['name_tag'])}\")\nprint(f\"Without name token: {len(up_dataset)-sum(up_dataset['name_tag'])}\")\n\nprint(\"\\n.......downsampled data.......\")\nprint(f\"With name token: {sum(down_dataset['name_tag'])}\")\nprint(f\"Without name token: {len(down_dataset)-sum(down_dataset['name_tag'])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T16:38:19.110629Z","iopub.execute_input":"2025-10-14T16:38:19.111166Z","iopub.status.idle":"2025-10-14T16:38:19.117257Z","shell.execute_reply.started":"2025-10-14T16:38:19.111143Z","shell.execute_reply":"2025-10-14T16:38:19.116354Z"}},"outputs":[{"name":"stdout","text":"Dataset shape: \nupsampled: (3618, 3), downsampled: (1652, 3), original train: (4612, 2)\n\n.......upsampled data.......\nWith name token : 827\nWithout name token: 2791\n\n.......downsampled data.......\nWith name token: 826\nWithout name token: 826\n","output_type":"stream"}],"execution_count":131},{"cell_type":"code","source":"if CONFIG.debug:\n    data= dataset[['sentences', 'labels']][: CONFIG.dataset_size]\nelse:\n    data= dataset[['sentences', 'labels']]\n\ndata['name_tag']= data['labels'].apply(lambda x: 1 if x.count(\"B-NAME\")>0 else 0)","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:28:26.750500Z","iopub.execute_input":"2025-10-14T22:28:26.750822Z","iopub.status.idle":"2025-10-14T22:28:26.759907Z","shell.execute_reply.started":"2025-10-14T22:28:26.750799Z","shell.execute_reply":"2025-10-14T22:28:26.759278Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"print(data.shape)\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T22:28:29.164060Z","iopub.execute_input":"2025-10-14T22:28:29.164847Z","iopub.status.idle":"2025-10-14T22:28:29.173663Z","shell.execute_reply.started":"2025-10-14T22:28:29.164822Z","shell.execute_reply":"2025-10-14T22:28:29.173037Z"}},"outputs":[{"name":"stdout","text":"(5582, 3)\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                                           sentences  \\\n0  আশঙ্কাজনক অবস্থায় উপজেলা স্বাস্থ্য কমপ্লেক্সে...   \n1  খুলনার দিঘলিয়া উপজেলার বারাকপুর মধ্যপাড়ায় গ...   \n2  পুলিশের পিটুনিতে কেসমত আলীর মৃত্যু হয়েছে বলে ...   \n3  তবে পুলিশ বলছে , ওই ব্যক্তি পুলিশ দেখে পড়ে গে...   \n4  কেসমতের পরিবার , এলাকাবাসী ও পুলিশ সূত্রে জানা...   \n\n                                              labels  name_tag  \n0                  [O, O, O, O, O, O, O, O, O, O, O]         0  \n1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...         1  \n2        [O, O, B-NAME, I-NAME, O, O, O, O, O, O, O]         1  \n3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]         0  \n4  [B-NAME, O, O, O, O, O, O, O, O, O, O, O, O, O...         1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentences</th>\n      <th>labels</th>\n      <th>name_tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>আশঙ্কাজনক অবস্থায় উপজেলা স্বাস্থ্য কমপ্লেক্সে...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>খুলনার দিঘলিয়া উপজেলার বারাকপুর মধ্যপাড়ায় গ...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>পুলিশের পিটুনিতে কেসমত আলীর মৃত্যু হয়েছে বলে ...</td>\n      <td>[O, O, B-NAME, I-NAME, O, O, O, O, O, O, O]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>তবে পুলিশ বলছে , ওই ব্যক্তি পুলিশ দেখে পড়ে গে...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>কেসমতের পরিবার , এলাকাবাসী ও পুলিশ সূত্রে জানা...</td>\n      <td>[B-NAME, O, O, O, O, O, O, O, O, O, O, O, O, O...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"print(f\"With name token: {sum(data['name_tag'])}\")\nprint(f\"Without name token: {len(data)-sum(data['name_tag'])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T22:28:32.175734Z","iopub.execute_input":"2025-10-14T22:28:32.176464Z","iopub.status.idle":"2025-10-14T22:28:32.181466Z","shell.execute_reply.started":"2025-10-14T22:28:32.176438Z","shell.execute_reply":"2025-10-14T22:28:32.180622Z"}},"outputs":[{"name":"stdout","text":"With name token: 2791\nWithout name token: 2791\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# checking every entry has exact number of labels corresponding to its words \nb_tokenizer= BasicTokenizer()\ndata['len_labels']= data['labels'].apply(lambda x: len(x))\ndata['len_words']= data['sentences'].apply(lambda x: len(b_tokenizer.tokenize(x)))","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:28:34.851956Z","iopub.execute_input":"2025-10-14T22:28:34.852248Z","iopub.status.idle":"2025-10-14T22:28:35.111036Z","shell.execute_reply.started":"2025-10-14T22:28:34.852226Z","shell.execute_reply":"2025-10-14T22:28:35.110471Z"},"trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T22:28:37.692955Z","iopub.execute_input":"2025-10-14T22:28:37.693479Z","iopub.status.idle":"2025-10-14T22:28:37.702513Z","shell.execute_reply.started":"2025-10-14T22:28:37.693454Z","shell.execute_reply":"2025-10-14T22:28:37.701629Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                           sentences  \\\n0  আশঙ্কাজনক অবস্থায় উপজেলা স্বাস্থ্য কমপ্লেক্সে...   \n1  খুলনার দিঘলিয়া উপজেলার বারাকপুর মধ্যপাড়ায় গ...   \n2  পুলিশের পিটুনিতে কেসমত আলীর মৃত্যু হয়েছে বলে ...   \n3  তবে পুলিশ বলছে , ওই ব্যক্তি পুলিশ দেখে পড়ে গে...   \n4  কেসমতের পরিবার , এলাকাবাসী ও পুলিশ সূত্রে জানা...   \n\n                                              labels  name_tag  len_labels  \\\n0                  [O, O, O, O, O, O, O, O, O, O, O]         0          11   \n1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...         1          27   \n2        [O, O, B-NAME, I-NAME, O, O, O, O, O, O, O]         1          11   \n3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]         0          14   \n4  [B-NAME, O, O, O, O, O, O, O, O, O, O, O, O, O...         1          28   \n\n   len_words  \n0         11  \n1         27  \n2         11  \n3         14  \n4         28  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentences</th>\n      <th>labels</th>\n      <th>name_tag</th>\n      <th>len_labels</th>\n      <th>len_words</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>আশঙ্কাজনক অবস্থায় উপজেলা স্বাস্থ্য কমপ্লেক্সে...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>0</td>\n      <td>11</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>খুলনার দিঘলিয়া উপজেলার বারাকপুর মধ্যপাড়ায় গ...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n      <td>1</td>\n      <td>27</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>পুলিশের পিটুনিতে কেসমত আলীর মৃত্যু হয়েছে বলে ...</td>\n      <td>[O, O, B-NAME, I-NAME, O, O, O, O, O, O, O]</td>\n      <td>1</td>\n      <td>11</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>তবে পুলিশ বলছে , ওই ব্যক্তি পুলিশ দেখে পড়ে গে...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>0</td>\n      <td>14</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>কেসমতের পরিবার , এলাকাবাসী ও পুলিশ সূত্রে জানা...</td>\n      <td>[B-NAME, O, O, O, O, O, O, O, O, O, O, O, O, O...</td>\n      <td>1</td>\n      <td>28</td>\n      <td>28</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"data_ = data.copy()\n\nskf= StratifiedKFold(n_splits= CONFIG.n_folds, random_state= CONFIG.seed, shuffle= True)\n\nfor fold, (train_index, val_index) in enumerate(skf.split(X= data_, y= data_['name_tag'])):\n    data_.loc[val_index, 'fold']= int(fold)\n    \ndata_['fold']= data_['fold'].astype(int)\n\ndata_= data_[['sentences', 'labels', 'fold']]\n\nprint(data_.groupby('fold').size())","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:28:40.514719Z","iopub.execute_input":"2025-10-14T22:28:40.515291Z","iopub.status.idle":"2025-10-14T22:28:40.529175Z","shell.execute_reply.started":"2025-10-14T22:28:40.515265Z","shell.execute_reply":"2025-10-14T22:28:40.528500Z"},"trusted":true},"outputs":[{"name":"stdout","text":"fold\n0    1861\n1    1861\n2    1860\ndtype: int64\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"data_.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T22:28:44.544054Z","iopub.execute_input":"2025-10-14T22:28:44.544700Z","iopub.status.idle":"2025-10-14T22:28:44.553200Z","shell.execute_reply.started":"2025-10-14T22:28:44.544674Z","shell.execute_reply":"2025-10-14T22:28:44.552381Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                                           sentences  \\\n0  আশঙ্কাজনক অবস্থায় উপজেলা স্বাস্থ্য কমপ্লেক্সে...   \n1  খুলনার দিঘলিয়া উপজেলার বারাকপুর মধ্যপাড়ায় গ...   \n2  পুলিশের পিটুনিতে কেসমত আলীর মৃত্যু হয়েছে বলে ...   \n3  তবে পুলিশ বলছে , ওই ব্যক্তি পুলিশ দেখে পড়ে গে...   \n4  কেসমতের পরিবার , এলাকাবাসী ও পুলিশ সূত্রে জানা...   \n\n                                              labels  fold  \n0                  [O, O, O, O, O, O, O, O, O, O, O]     2  \n1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...     0  \n2        [O, O, B-NAME, I-NAME, O, O, O, O, O, O, O]     1  \n3         [O, O, O, O, O, O, O, O, O, O, O, O, O, O]     2  \n4  [B-NAME, O, O, O, O, O, O, O, O, O, O, O, O, O...     0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentences</th>\n      <th>labels</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>আশঙ্কাজনক অবস্থায় উপজেলা স্বাস্থ্য কমপ্লেক্সে...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>খুলনার দিঘলিয়া উপজেলার বারাকপুর মধ্যপাড়ায় গ...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>পুলিশের পিটুনিতে কেসমত আলীর মৃত্যু হয়েছে বলে ...</td>\n      <td>[O, O, B-NAME, I-NAME, O, O, O, O, O, O, O]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>তবে পুলিশ বলছে , ওই ব্যক্তি পুলিশ দেখে পড়ে গে...</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>কেসমতের পরিবার , এলাকাবাসী ও পুলিশ সূত্রে জানা...</td>\n      <td>[B-NAME, O, O, O, O, O, O, O, O, O, O, O, O, O...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"label_names=['O', 'B-NAME', 'I-NAME']\nid2label= {}\nlabel2id= {}\nfor i, label in enumerate(label_names):\n    id2label[i]= label\n    label2id[label] = i\n\ndisplay(id2label)\ndisplay(label2id)","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:28:47.959872Z","iopub.execute_input":"2025-10-14T22:28:47.960159Z","iopub.status.idle":"2025-10-14T22:28:47.967051Z","shell.execute_reply.started":"2025-10-14T22:28:47.960128Z","shell.execute_reply":"2025-10-14T22:28:47.966152Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"{0: 'O', 1: 'B-NAME', 2: 'I-NAME'}"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"{'O': 0, 'B-NAME': 1, 'I-NAME': 2}"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(CONFIG.model_name)","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:29:00.159395Z","iopub.execute_input":"2025-10-14T22:29:00.159784Z","iopub.status.idle":"2025-10-14T22:29:00.508189Z","shell.execute_reply.started":"2025-10-14T22:29:00.159762Z","shell.execute_reply":"2025-10-14T22:29:00.507375Z"},"trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def align_labels_with_tokens(tokens, labels):\n    new_labels = []\n    word_ids = tokens.word_ids()\n    previous_word_id = None\n    \n    for word_id in word_ids:\n        if word_id is None or word_id >= len(labels):\n            # Special token or truncated word: ignore\n            label = -100\n        elif word_id != previous_word_id:\n            label = label2id[labels[word_id]]\n        else:\n            # Repeated subword token\n            label = -100\n        previous_word_id = word_id\n        new_labels.append(label)\n    \n    return new_labels","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:29:03.365257Z","iopub.execute_input":"2025-10-14T22:29:03.365991Z","iopub.status.idle":"2025-10-14T22:29:03.370825Z","shell.execute_reply.started":"2025-10-14T22:29:03.365964Z","shell.execute_reply":"2025-10-14T22:29:03.369985Z"},"trusted":true},"outputs":[],"execution_count":30},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, df, tokenizer, cfg):\n        self.df= df\n        self.cfg= cfg\n        self.tokenizer= tokenizer\n        self.max_length= self.cfg.max_length\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text= self.df.sentences[index]\n        labels= self.df.labels[index]\n        inputs= self.tokenizer(text, truncation= True, max_length= self.max_length, padding= True)\n        new_labels= align_labels_with_tokens(inputs, labels)\n        \n        return {\n            'input_ids': inputs['input_ids'],\n            'attention_mask': inputs['attention_mask'],\n            'targets': new_labels            \n        }","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:29:06.780237Z","iopub.execute_input":"2025-10-14T22:29:06.781065Z","iopub.status.idle":"2025-10-14T22:29:06.786115Z","shell.execute_reply.started":"2025-10-14T22:29:06.781038Z","shell.execute_reply":"2025-10-14T22:29:06.785255Z"},"trusted":true},"outputs":[],"execution_count":31},{"cell_type":"code","source":"class Collate:\n    \n    def __init__(self, tokenizer):\n        self.tokenizer= tokenizer\n    \n    def __call__(self, batch):\n        output= dict()\n        output['input_ids'] = [sample['input_ids'] for sample in batch]\n        output['attention_mask'] = [sample['attention_mask'] for sample in batch]\n        output['targets'] = [sample['targets'] for sample in batch]\n        \n        batch_max= max([len(ids) for ids in output['input_ids']])\n        \n        # dynamic padding\n        if self.tokenizer.padding_side == 'right':\n            output['input_ids'] = [ids + (batch_max - len(ids))*[self.tokenizer.pad_token_id] for ids in output['input_ids']]\n            output['attention_mask']= [mask + (batch_max - len(mask))*[0] for mask in output['attention_mask']]\n            output['targets']= [target + (batch_max - len(target))*[-100] for target in output['targets']]\n        else:\n            output['input_ids'] = [(batch_max - len(ids))*[self.tokenizer.pad_token_id] + ids for ids in output['input_ids']]\n            output['attention_mask']= [(batch_max - len(mask))*[0] + mask for mask in output['attention_mask']]\n            output['targets']= [(batch_max - len(target))*[-100] + target for target in output['targets']]\n        \n        output['input_ids'] = torch.tensor(output['input_ids'], dtype= torch.long)\n        output['attention_mask'] = torch.tensor(output['attention_mask'], dtype= torch.long)\n        output['targets'] = torch.tensor(output['targets'], dtype=torch.long)\n        \n        return output\n    \n\ncollate_fn= Collate(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:29:09.792043Z","iopub.execute_input":"2025-10-14T22:29:09.792781Z","iopub.status.idle":"2025-10-14T22:29:09.800231Z","shell.execute_reply.started":"2025-10-14T22:29:09.792760Z","shell.execute_reply":"2025-10-14T22:29:09.799200Z"},"trusted":true},"outputs":[],"execution_count":32},{"cell_type":"code","source":"def prepare_loader(df, tokenizer,fold, cfg):\n    df_train= df[df.fold != fold].reset_index(drop= True) \n    df_valid= df[df.fold == fold].reset_index(drop= True)\n    valid_labels = df_valid['labels'].values\n    \n    # converting dataFrame to dataset.\n    train_dataset= CustomDataset(df_train, tokenizer, cfg)\n    valid_dataset= CustomDataset(df_valid, tokenizer, cfg)\n    \n    train_loader= DataLoader(train_dataset, \n                             batch_size= cfg.train_batch_size, \n                             collate_fn= collate_fn, \n                             num_workers= cfg.num_workers, \n                             shuffle= True, \n                             pin_memory= True,\n                             drop_last= False, )\n    \n    valid_loader= DataLoader(valid_dataset, \n                            batch_size= cfg.valid_batch_size,\n                            collate_fn= collate_fn, \n                            num_workers= cfg.num_workers,\n                            shuffle= False,\n                            pin_memory= True, \n                            drop_last= False,\n                            )\n    \n    return train_loader, valid_loader","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:29:12.778683Z","iopub.execute_input":"2025-10-14T22:29:12.779530Z","iopub.status.idle":"2025-10-14T22:29:12.785414Z","shell.execute_reply.started":"2025-10-14T22:29:12.779488Z","shell.execute_reply":"2025-10-14T22:29:12.784457Z"},"trusted":true},"outputs":[],"execution_count":33},{"cell_type":"code","source":"class NER_MODEL(nn.Module):\n    def __init__(self, model_name= None, cfg= CONFIG):\n        super(NER_MODEL, self).__init__()\n        self.cfg= cfg\n        self.num_labels= self.cfg.num_labels\n        if model_name != None:\n            self.model_name= model_name\n        else:\n            self.model_name= self.cfg.model_name\n            \n        self.model_config= AutoConfig.from_pretrained(self.model_name, output_hidden_states= True)\n        self.model= AutoModel.from_pretrained(self.model_name, config= self.model_config)\n        \n        self.dropout= nn.Dropout(p= 0.2)\n        self.linear= nn.Linear(self.model_config.hidden_size, self.num_labels)\n\n\n    \n    def forward(self, input_ids, attention_mask, targets= None):\n        \n        outputs= self.model(input_ids,\n                            attention_mask= attention_mask)\n        \n        sequence_output= outputs[0]\n\n        entity_logits= self.dropout(sequence_output)\n        # entity_logits= sequence_output #self.dropout(sequence_output)\n        entity_logits= self.linear(entity_logits)\n        \n        return entity_logits","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:29:15.657335Z","iopub.execute_input":"2025-10-14T22:29:15.657890Z","iopub.status.idle":"2025-10-14T22:29:15.663461Z","shell.execute_reply.started":"2025-10-14T22:29:15.657859Z","shell.execute_reply":"2025-10-14T22:29:15.662713Z"},"trusted":true},"outputs":[],"execution_count":34},{"cell_type":"code","source":"import evaluate\nmetric = evaluate.load(\"seqeval\")\nprint(\"Seqeval metric loaded successfully\")\n\ndef compute_metrics(logits, labels):\n    predictions = np.argmax(logits.detach().cpu().numpy(), axis=-1)\n\n    # Remove ignored index (special tokens) and convert to labels\n    true_labels = [[ label_names[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)]\n    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n    \n    return all_metrics['overall_f1']\n\n\ndef token_loss_fn(logits, labels, attention_mask= None):\n    loss_fn= nn.CrossEntropyLoss(ignore_index= -100) \n    num_labels= CONFIG.num_labels\n    \n    if attention_mask is not None:\n        mask= attention_mask.view(-1) == 1   # mask for keeping the effective part\n        active_logits= logits.view(-1, num_labels)[mask]\n        active_labels= labels.view(-1)[mask]\n        entity_loss= loss_fn(active_logits, active_labels)\n    else:\n        entity_loss= loss_fn(logits.view(-1, num_labels), labels.view(-1))\n    \n    return entity_loss","metadata":{"execution":{"iopub.status.busy":"2025-10-14T23:35:03.826510Z","iopub.execute_input":"2025-10-14T23:35:03.827291Z","iopub.status.idle":"2025-10-14T23:35:05.211224Z","shell.execute_reply.started":"2025-10-14T23:35:03.827264Z","shell.execute_reply":"2025-10-14T23:35:05.210565Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Seqeval metric loaded successfully\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"def fetch_scheduler(optimizer):\n    if CONFIG.scheduler == \"CosineAnnealingLR\":\n        scheduler= lr_scheduler.CosineAnnealingLR(optimizer, T_max= CONFIG.T_max, eta_min= CONFIG.min_lr)\n    elif CONFIG.scheduler == \"CosineAnnealingWarmRestarts\":\n        scheduler= lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0= CONFIG.T_0, eta_min= CONFIG.min_lr)\n    elif CONFIG.scheduler== \"linear\":\n        scheduler= lr_scheduler.LinearLR(optimizer, start_factor= 0.01, end_factor= 1.0, total_iters= 100)\n    elif CONFIG.scheduler == None:\n        return None\n\n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:29:21.653855Z","iopub.execute_input":"2025-10-14T22:29:21.654140Z","iopub.status.idle":"2025-10-14T22:29:21.658935Z","shell.execute_reply.started":"2025-10-14T22:29:21.654118Z","shell.execute_reply":"2025-10-14T22:29:21.658173Z"},"trusted":true},"outputs":[],"execution_count":36},{"cell_type":"code","source":"def train_one_epoch(model, dataloader, optimizer, scheduler, fold, epoch, device= CONFIG.device):\n    model.train()\n\n    dataset_size= 0\n    running_loss= 0.0\n    score= []\n    \n    progress_bar= tqdm(enumerate(dataloader), total= len(dataloader))\n    steps= len(dataloader)\n    for step, data in progress_bar:\n        ids= data['input_ids'].to(device, dtype= torch.long)\n        masks= data['attention_mask'].to(device, dtype= torch.long)\n        targets= data['targets'].to(device, dtype= torch.long)\n        \n        batch_size= ids.size(0)\n        outputs= model(ids, masks)\n        loss= token_loss_fn(outputs, targets, attention_mask= masks)\n        f1_score= compute_metrics(logits= outputs, labels= targets)\n        score.append(f1_score)\n        if CONFIG.gradient_accumulation_steps > 1:\n            loss= loss/ CONFIG.gradient_accumulation_steps\n        \n        loss.backward()\n        ## Gradient Accumulation\n        if (step + 1) % CONFIG.gradient_accumulation_steps == 0 or step == steps:\n            optimizer.step() \n            optimizer.zero_grad()\n            \n            if scheduler is not None:\n                scheduler.step()\n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        epoch_loss= running_loss/ dataset_size\n        epoch_f1_score= np.mean(score)\n        \n        progress_bar.set_postfix(Epoch= epoch,\n                                 Train_loss= epoch_loss,\n                                 F1_Score= epoch_f1_score,\n                                 LR= optimizer.param_groups[0]['lr'])\n    \n    return epoch_loss, epoch_f1_score ","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:29:24.034395Z","iopub.execute_input":"2025-10-14T22:29:24.035019Z","iopub.status.idle":"2025-10-14T22:29:24.042015Z","shell.execute_reply.started":"2025-10-14T22:29:24.034995Z","shell.execute_reply":"2025-10-14T22:29:24.040999Z"},"trusted":true},"outputs":[],"execution_count":37},{"cell_type":"code","source":"def valid_one_epoch(model, dataloader, epoch, device= CONFIG.device):\n    model.eval()\n    \n    dataset_size= 0\n    running_loss= 0.0\n    score= []\n    \n    progress_bar= tqdm(enumerate(dataloader), total= len(dataloader))\n    steps= len(dataloader)\n    \n    for step, data in progress_bar:\n        ids= data['input_ids'].to(device, dtype= torch.long)\n        masks= data['attention_mask'].to(device, dtype= torch.long)\n        targets= data['targets'].to(device, dtype= torch.long)\n        \n        batch_size= ids.size(0)\n        \n        with torch.no_grad():\n            outputs= model(ids, masks)\n            loss= token_loss_fn(outputs, targets, attention_mask= masks)\n            f1_score= compute_metrics(logits= outputs, labels= targets)\n        \n        score.append(f1_score)\n        \n        if CONFIG.gradient_accumulation_steps > 1:\n            loss= loss/ CONFIG.gradient_accumulation_steps\n        \n        \n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        epoch_loss= running_loss/ dataset_size\n        epoch_f1_score= np.mean(score)\n        \n        progress_bar.set_postfix(Epoch= epoch,\n                                 Valid_loss= epoch_loss,\n                                 Valid_F1_Score= epoch_f1_score)\n        \n    return epoch_loss, epoch_f1_score ","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:29:28.503350Z","iopub.execute_input":"2025-10-14T22:29:28.503917Z","iopub.status.idle":"2025-10-14T22:29:28.510117Z","shell.execute_reply.started":"2025-10-14T22:29:28.503892Z","shell.execute_reply":"2025-10-14T22:29:28.509278Z"},"trusted":true},"outputs":[],"execution_count":38},{"cell_type":"code","source":"import time\nfrom collections import defaultdict\ndef training_loop(model, optimizer, scheduler, fold, num_epochs= CONFIG.num_epochs, patience= 3):\n    \n    start= time.time()\n    best_loss= np.inf\n    best_score= 0\n    trigger_times= 0\n    history= defaultdict(list)\n    \n    for epoch in range(1, num_epochs+1):\n        # ---- Training Phase ----\n        train_epoch_loss, train_f1_score= train_one_epoch(model, train_loader, optimizer, scheduler, fold, epoch, CONFIG.device)\n        # ---- Validation Phase ----\n        valid_epoch_loss, valid_f1_score = valid_one_epoch(model, valid_loader, epoch, CONFIG.device)\n\n        # ---- Track metrics ----\n        history['train_loss'].append(train_epoch_loss)\n        history['valid_loss'].append(valid_epoch_loss)\n        history['train_f1_score'].append(train_f1_score)\n        history['valid_f1_score'].append(valid_f1_score)\n        \n        # ---- Model checkpointing ----\n        if  valid_f1_score >= best_score: \n            trigger_times= 0\n            print(f\"Validation Score Improved {best_score:.4f} ---> {valid_f1_score:.4f}\")\n            best_score= valid_f1_score\n            \n            path= f\"best_model_{fold}.bin\"\n            torch.save(model.state_dict(), path)\n            print(f\"Model saved to {path}\")\n        else:\n            trigger_times += 1\n            if trigger_times >= patience:\n                print(\"Early Stoping. \\n\")\n                break\n                \n    time_elapsed= time.time() - start\n    print(f\"\\nTraining complete in {time_elapsed // 3600:.0f}h {(time_elapsed % 3600) // 60:.0f}m {(time_elapsed % 60):.0f}s\")\n\n    \n    return history, valid_epoch_loss, best_score","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:29:32.896314Z","iopub.execute_input":"2025-10-14T22:29:32.896620Z","iopub.status.idle":"2025-10-14T22:29:32.903322Z","shell.execute_reply.started":"2025-10-14T22:29:32.896570Z","shell.execute_reply":"2025-10-14T22:29:32.902513Z"},"trusted":true},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"### Run Training","metadata":{},"attachments":{}},{"cell_type":"code","source":"if CONFIG.train:\n    fold_scores= []\n    for fold in range(CONFIG.n_folds):\n        torch.cuda.empty_cache()\n        print(f\"====== Fold: {fold} ======\")\n\n        train_loader, valid_loader = prepare_loader(data_, tokenizer, fold= fold, cfg= CONFIG)\n\n        model= NER_MODEL(cfg= CONFIG)\n        model.to(device= CONFIG.device)\n\n        optimizer= AdamW(model.parameters(), lr= CONFIG.learning_rate, weight_decay= CONFIG.weight_decay, eps= CONFIG.eps, betas= CONFIG.betas)\n        scheduler= fetch_scheduler(optimizer)\n\n        history, epoch_loss, f1_score= training_loop(model, optimizer, scheduler, fold, CONFIG.num_epochs, patience= 5)#epoch_loss\n\n        print(\"\\n\\n\")\n        print(f\"Fold [{fold}] avg loss: {epoch_loss}\\n\")\n        print(f\"Fold [{fold}] avg score: {f1_score}\\n\")\n        fold_scores.append(f1_score)\n        \n        if fold < CONFIG.n_folds-1:\n            del model\n        del train_loader, valid_loader\n\n    print(f\"====== ====== ====== ======\")\n    print(f\"Overall score: {np.mean(np.mean(fold_scores, axis= 0))}\")\n    print(f\"====== ====== ====== ======\")","metadata":{"execution":{"iopub.status.busy":"2025-10-14T22:29:37.070384Z","iopub.execute_input":"2025-10-14T22:29:37.071087Z","iopub.status.idle":"2025-10-14T23:31:04.393038Z","shell.execute_reply.started":"2025-10-14T22:29:37.071062Z","shell.execute_reply":"2025-10-14T23:31:04.392298Z"},"trusted":true},"outputs":[{"name":"stdout","text":"====== Fold: 0 ======\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0d2125c593c4044ab928d09ffefe048"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"492ade18b3cd402aa8a14783bf73fd24"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.0000 ---> 0.8338\nModel saved to best_model_0.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82cfe4545f114a8cb439ab14dde6e965"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ae5e4dadb1943d183503b436502ce11"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8338 ---> 0.8410\nModel saved to best_model_0.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45e42cc86cac4a73929beb15c305643c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3728a486c0444a58bf85e48dd942b34"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8410 ---> 0.8472\nModel saved to best_model_0.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b72cc861c8b34c9db1c65bb338507faf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07f93d22025f40c1afa31af19b55d24d"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8472 ---> 0.8535\nModel saved to best_model_0.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a75f4239e5ea4d8d9f52718c9d83cd23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b7f56602a994eac8b134ec16fdfb15e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa8f578826a34fcda087c953c0ac8151"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8e31a695de84cadbaa237ee936d0d07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18e88c55bb0740a6945793316ace93d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3244c0a866304398bba34331cf7b8b63"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8535 ---> 0.8540\nModel saved to best_model_0.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1294a98e632c493192ee1d7526a3e160"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d875c986b72c4dfca04f484d1181d3d5"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8540 ---> 0.8643\nModel saved to best_model_0.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d85b90ca8d94d53b5a6670080834168"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a70c7846f9a47708595d1798ecf13d4"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8643 ---> 0.8774\nModel saved to best_model_0.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3534b68c92054f35ae130ffb571ae692"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de1dcc616de44c4b805a27d99b59c638"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8774 ---> 0.8818\nModel saved to best_model_0.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c91491619202484582bc26ece15c04ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cff37aaa386f4b0486e24fe823113ad2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc533dd09a5d480e992b7ea44b2b7000"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43bbb8cf09994896867f71d497def58d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b29dd525915541c88a965b8bab9ccf0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6b707a7b91d4377a5764db393d62a39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d6b452881cd47e586dcd944b0032c45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55903ae80dd64d398bfdcf97e453f197"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f614d3f8297e462288a5dad6136e9046"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41b3b98df74f40fcb294f56647b01ffd"}},"metadata":{}},{"name":"stdout","text":"Early Stoping. \n\n\nTraining complete in 0h 16m 23s\n\n\n\nFold [0] avg loss: 0.01152227494580967\n\nFold [0] avg score: 0.8818110802050969\n\n====== Fold: 1 ======\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09f7268e12f64b868edc3e0ca567039a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56c1cb9dd65440668e3271af2676b988"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.0000 ---> 0.7985\nModel saved to best_model_1.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc30cc528cd94f4196a61670916d920e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d03f6a7a00044e09e3a597496a863f0"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.7985 ---> 0.8063\nModel saved to best_model_1.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee14d5b442e2495393d8abdcc1c4d687"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e07bfe32575414db4d7d96d04cdc57f"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8063 ---> 0.8176\nModel saved to best_model_1.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aeaf9781303b40c5b76d0a090b00fec9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57a6ea68cfc04ba4ba4e5bfa4cb23c81"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8176 ---> 0.8247\nModel saved to best_model_1.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb66c86fe87446878379e1c3be25c0d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e23cffb7cd7145109a6ad20ed973b10d"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8247 ---> 0.8329\nModel saved to best_model_1.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f9155773c584f6c85cc2a40a2703ebe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9edae46cc7f14c719fc090fd8bb0cb0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27d2df45d35e4e9aa2936424dbccaf31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8e4578e88b84a8fa28cc31a6ec3136c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bd01b1083c543408b812c41d9c551cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10611c0a56cf4ae490e7096b14fd446a"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8329 ---> 0.8330\nModel saved to best_model_1.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"010f292f0833453eac4c20f5ea3a8624"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4512af8b7d714556b372d296e8fa0761"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4bfaaddadce455987b49b47752c8f4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99ac05dedd03440d84634768c6464570"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa318b971448483ab8f0515288dbd4f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da5cad8137a54e55af8120451608d3c5"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8330 ---> 0.8340\nModel saved to best_model_1.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb4d4688a4ac4ea8b71e5a4ccf571fbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a276349e38f94f388a71b4130a8648b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"356564da1f32478a9c153d845e7fd878"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29e46d441a1a4ca5847168aae17c931f"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8340 ---> 0.8361\nModel saved to best_model_1.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94a0dd5127d04a3db2f8e36c1b34c29d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02383561447c4c449307c9329e3415cd"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8361 ---> 0.8368\nModel saved to best_model_1.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39323a20575b4f4f946e04d3781ff07f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad9b38f0580046a8ae94fa3782bd387d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7e173a7c15d41d38fb6d1df14914936"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2cf3ad930b14b1e8f6fb9c53b20f163"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6988899932394f39bb091e6d40c23ad4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6485c68b12674e93aa5c92210e7365db"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8368 ---> 0.8414\nModel saved to best_model_1.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5667f01e190451a8adc5ab1afd53faa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce6466b6ad8a4a47b67f9f90d080e57f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"648b4f0a71a344109a1767c44443621e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0af224b04b864ceab86542e67a1b95aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"984810d1951443a0a094a7d1191b1db0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bba0e43ab684712a22e0a5c999fbbe9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47e23e3ae1ce4acfb177afd177e29961"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0144623ea997477da673791b19ecad81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22be860e7a4e4f0f84089ec5e323e309"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e15beac9c6e43ecbf99f358b7fa6f9f"}},"metadata":{}},{"name":"stdout","text":"Early Stoping. \n\n\nTraining complete in 0h 24m 9s\n\n\n\nFold [1] avg loss: 0.01669692062667999\n\nFold [1] avg score: 0.8413742553524662\n\n====== Fold: 2 ======\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9a785fddaaf47dfa458d051bcda722e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a9e9271a4534058abc94cb11e08a57d"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.0000 ---> 0.7967\nModel saved to best_model_2.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c33caadb79894710addc3e161918be1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c08f8915461473e9d82cf159b36e6e2"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.7967 ---> 0.7970\nModel saved to best_model_2.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e87f32acb274ae8b26bce814e76e9b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"719d9d9065fd4027907bc5a55c14faa9"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.7970 ---> 0.8125\nModel saved to best_model_2.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db590b398f444d608e4356666648820f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab8559824f894d569fc5643405a2b7aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"488166547b7f4420a7523eed0d2e5e82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3ed598dc1b847ad86311485226c8751"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8125 ---> 0.8134\nModel saved to best_model_2.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34b15164ab4e4351af0e436b12295d2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42079caa8f3a47dda823d31122e7bc74"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8134 ---> 0.8334\nModel saved to best_model_2.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e6bdd4240584f4f9160a51b60505234"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ffcab021772486db8a2bce888fa2eeb"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8334 ---> 0.8400\nModel saved to best_model_2.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b21e29deedb14f299fb6cadd416ced45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3a3325f141e4adf8e4e3c0f613ee48c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c428077edb34c5a9fb211740b3c28c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90423f899d1a4c1b8b96fe036a4d2ff3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c79c37ee7f8c4eb7b9d799e32eb9fff7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3df75ce752e4fdcb8dccea38af46120"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8400 ---> 0.8414\nModel saved to best_model_2.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"737b2698c9724f8189b74ccbaea6456d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a7802fabeaf483aa9218c087eff549a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b5e5a24a5cc4de0937be70dde8e842d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92ca814267c342cc9d2f8189f6855991"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8414 ---> 0.8459\nModel saved to best_model_2.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3054ab94feec4e1f86530d76dc245c01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"219e8e4a03134f5c8e956edc0f64b86e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a01fb970e3164dd9b0766a97eeb21663"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c57206a044c8486880c737cce736e0e3"}},"metadata":{}},{"name":"stdout","text":"Validation Score Improved 0.8459 ---> 0.8503\nModel saved to best_model_2.bin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d4610c04f914e77906696c609fa13d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b667055a1ab64822aab39c9406f3eb30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bddd64cbb9c45e7960fa7edfb6cd315"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea072ce42f844fbf847a2766b5f20bd5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"261c43a571ea4860b2d97dba0ec7e89d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18e9e866fe6a487687ccbd1667e117b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0d14b4d69a14011aee8bc6c98a62316"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42288558dddd4dd5b942f60361638497"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/466 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01d1d11db10048fe84647d3ed376711a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/117 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfa433e8d4464735a601351581446063"}},"metadata":{}},{"name":"stdout","text":"Early Stoping. \n\n\nTraining complete in 0h 20m 52s\n\n\n\nFold [2] avg loss: 0.025874755348359618\n\nFold [2] avg score: 0.8502798885380481\n\n====== ====== ====== ======\nOverall score: 0.8578217413652037\n====== ====== ====== ======\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## Testing","metadata":{},"attachments":{}},{"cell_type":"code","source":"from tqdm.auto import tqdm\ndef testing_loop(model, dataloader, device= CONFIG.device):\n    model.eval()\n    \n    score= []\n    \n    progress_bar= tqdm(enumerate(dataloader), total= len(dataloader))\n    steps= len(dataloader)\n    \n    for step, data in progress_bar:\n        ids= data['input_ids'].to(device, dtype= torch.long)\n        masks= data['attention_mask'].to(device, dtype= torch.long)\n        targets= data['targets'].to(device, dtype= torch.long)\n        \n        batch_size= ids.size(0)\n        \n        with torch.no_grad():\n            outputs= model(ids, masks)\n            f1_score= compute_metrics(logits= outputs, labels= targets)\n        \n        score.append(f1_score)\n        \n        f1_score= np.mean(score)\n        \n        progress_bar.set_postfix(test_F1_Score= f1_score,)\n    \n    print(f\"====== ====== ====== ======\")\n    print(f\"Overall f1_score: {np.mean(np.mean(f1_score))}\")\n    print(f\"====== ====== ====== ======\")\n\n    return f1_score ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T23:31:31.823286Z","iopub.execute_input":"2025-10-14T23:31:31.823999Z","iopub.status.idle":"2025-10-14T23:31:31.830405Z","shell.execute_reply.started":"2025-10-14T23:31:31.823971Z","shell.execute_reply":"2025-10-14T23:31:31.829629Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"test_dataset= CustomDataset(test_data, tokenizer, CONFIG)\ntest_loader= DataLoader(test_dataset, \n                        batch_size= CONFIG.test_batch_size,\n                        collate_fn= collate_fn, \n                        num_workers= CONFIG.num_workers,\n                        shuffle= False,\n                        pin_memory= True, \n                        drop_last= False,\n                        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T23:31:39.298081Z","iopub.execute_input":"2025-10-14T23:31:39.298329Z","iopub.status.idle":"2025-10-14T23:31:39.302781Z","shell.execute_reply.started":"2025-10-14T23:31:39.298313Z","shell.execute_reply":"2025-10-14T23:31:39.302118Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"model_paths= [\n    \"/kaggle/working/best_model_0.bin\",\n    \"/kaggle/working/best_model_1.bin\",\n    \"/kaggle/working/best_model_2.bin\"\n    ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T23:31:42.534766Z","iopub.execute_input":"2025-10-14T23:31:42.535055Z","iopub.status.idle":"2025-10-14T23:31:42.539376Z","shell.execute_reply.started":"2025-10-14T23:31:42.535030Z","shell.execute_reply":"2025-10-14T23:31:42.538602Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"model= NER_MODEL(cfg= CONFIG)\nfor i,model_path in enumerate(model_paths):\n    model.load_state_dict(torch.load(model_path, map_location= CONFIG.device))\n    model.to(CONFIG.device)\n    print(f\"Run testing for model {CONFIG.model_name}\")\n    f1_score= testing_loop(model, test_loader, device= CONFIG.device)\n    print(f\"Model {i} result: {f1_score}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T23:31:45.999962Z","iopub.execute_input":"2025-10-14T23:31:46.000700Z","iopub.status.idle":"2025-10-14T23:32:11.959280Z","shell.execute_reply.started":"2025-10-14T23:31:46.000674Z","shell.execute_reply":"2025-10-14T23:32:11.958565Z"}},"outputs":[{"name":"stdout","text":"Run testing for model celloscopeai/celloscope-28000-ner-banglabert-finetuned\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/91 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd642f6d02714406b88d8dfab441ceb0"}},"metadata":{}},{"name":"stdout","text":"====== ====== ====== ======\nOverall f1_score: 0.8357228470488637\n====== ====== ====== ======\nModel 0 result: 0.8357228470488637\nRun testing for model celloscopeai/celloscope-28000-ner-banglabert-finetuned\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/91 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19c833a389ba451d97f09e1e9cd9f73d"}},"metadata":{}},{"name":"stdout","text":"====== ====== ====== ======\nOverall f1_score: 0.8369379458726484\n====== ====== ====== ======\nModel 1 result: 0.8369379458726484\nRun testing for model celloscopeai/celloscope-28000-ner-banglabert-finetuned\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/91 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dd1dbe721a840e09d7b890c419f8969"}},"metadata":{}},{"name":"stdout","text":"====== ====== ====== ======\nOverall f1_score: 0.8349410558910031\n====== ====== ====== ======\nModel 2 result: 0.8349410558910031\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"## End to End Inference","metadata":{},"attachments":{}},{"cell_type":"code","source":"def prediction(text, model, tokenizer, cfg= CONFIG):\n    inputs= tokenizer.encode_plus(text, padding=True, truncation=True, return_tensors=\"pt\")\n    outputs= model(inputs['input_ids'].to(cfg.device), inputs['attention_mask'].to(cfg.device))\n    outputs= outputs.detach().cpu().numpy().argmax(axis= -1)[0, 1:-1]\n    return outputs\n\ndef inference_fn(text, model_name= None, model_checkpoint= None, cfg= CONFIG):\n    # loading model and weights\n    if model_name is not None:\n        tokenizer = AutoTokenizer.from_pretrained(model_name)\n        model= NER_MODEL(model_name= model_name, cfg= cfg)\n    else:\n        tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\n        model= NER_MODEL(cfg= CONFIG)\n        \n    if model_checkpoint != None:\n        model.load_state_dict(torch.load(model_checkpoint, map_location=  cfg.device))\n    else:\n        model.load_state_dict(torch.load(cfg.model_checkpoint, map_location=  cfg.device))\n    \n    model.to(cfg.device)\n    ## processing inputs\n    outputs=[]\n    if type(text) == str:\n        text= normalize(text)\n        output= prediction(text, model, tokenizer, cfg)\n        outputs.append(output)\n    elif type(text)== list:\n        for txt in text:\n            txt= normalize(txt)\n            output= prediction(txt, model, tokenizer, cfg)\n            outputs.append(output)      \n    else:\n        outputs= None\n        print(\"Please give input in string format or list of strings\")\n    \n    return outputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T23:32:16.997794Z","iopub.execute_input":"2025-10-14T23:32:16.998099Z","iopub.status.idle":"2025-10-14T23:32:17.005977Z","shell.execute_reply.started":"2025-10-14T23:32:16.998074Z","shell.execute_reply":"2025-10-14T23:32:17.005059Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"def extract_spans(prediction):\n    span_indices = [i for i, v in enumerate(prediction) if v != 0 ]\n    span_list= []\n    span= []\n    # span_indices\n    for i in range(len(span_indices)):\n        if i == 0 or span_indices[i] != span_indices[i-1]+1:\n            if span:\n                span_list.append(span)\n\n            span= [span_indices[i]]\n\n        else:\n            span.append(span_indices[i])\n    if span:\n        span_list.append(span)\n    \n    return span_list\n\ndef extract_names(text, span_list, tokenizer):\n    name_list= []\n    if len(span_list) > 0:\n        for span in span_list:\n            tokens= tokenizer(text)['input_ids'][1:-1][span[0]:span[-1]+1]\n            name= normalize(tokenizer.decode(tokens))\n            name_list.append(name)\n        return name_list\n    else:\n        return None\n\ndef show_names(texts, predictions, tokenizer):\n    if type(texts)== str:\n        texts= [texts]\n    for text, pred in zip(texts, predictions):\n        span_list= extract_spans(pred)\n        name_list= extract_names(text, span_list, tokenizer)\n        print(f\"Given Text: {text} \\nExtracted Names: {name_list}\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T23:32:20.936553Z","iopub.execute_input":"2025-10-14T23:32:20.936845Z","iopub.status.idle":"2025-10-14T23:32:20.943859Z","shell.execute_reply.started":"2025-10-14T23:32:20.936827Z","shell.execute_reply":"2025-10-14T23:32:20.943081Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"model_path= model_paths[0]\ntexts=  \"শিক্ষা মন্ত্রণালয়ের দায়িত্বশীল একটি সূত্রে জানা যায়, মুহাম্মদ আজাদ খানের বিষয়ে শিক্ষা মন্ত্রণালয়ের নীতিনির্ধারকেরা সন্তুষ্ট ছিলেন না।\" \ntexts= [\"অভিনেত্রী মন্দিরা চক্রবর্তীকে পূজার চার সাজে সাজানোর সময় ডিজাইনার হিসেবে আরাম, স্বকীয়তা আর স্বাচ্ছন্দ্যকে প্রাধান্য দিয়েছি বেশি। প্রতিটি সাজেই ছিল টেকসই নকশার ছোঁয়া।\",\n       \"শিল্প মন্ত্রণালয়ের সচিব মো. আব্দুর রহিম বলেন, পবিত্র রমজান মাস এলেই ব্যবসায়ীদের মধ্যে বেশি মুনাফা করার প্রবণতা তৈরি হয়।\",\n       \"শিক্ষা মন্ত্রণালয়ের দায়িত্বশীল একটি সূত্রে জানা যায়, মুহাম্মদ আজাদ খানের বিষয়ে শিক্ষা মন্ত্রণালয়ের নীতিনির্ধারকেরা সন্তুষ্ট ছিলেন না।\"\n      ]\n\noutputs= inference_fn(texts, model_checkpoint= model_path, cfg= CONFIG)\nshow_names(texts, outputs, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-14T23:32:24.398839Z","iopub.execute_input":"2025-10-14T23:32:24.399542Z","iopub.status.idle":"2025-10-14T23:32:26.304784Z","shell.execute_reply.started":"2025-10-14T23:32:24.399518Z","shell.execute_reply":"2025-10-14T23:32:26.304123Z"}},"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"Given Text: অভিনেত্রী মন্দিরা চক্রবর্তীকে পূজার চার সাজে সাজানোর সময় ডিজাইনার হিসেবে আরাম, স্বকীয়তা আর স্বাচ্ছন্দ্যকে প্রাধান্য দিয়েছি বেশি। প্রতিটি সাজেই ছিল টেকসই নকশার ছোঁয়া। \nExtracted Names: ['মন্দিরা চক্রবর্তীকে']\nGiven Text: শিল্প মন্ত্রণালয়ের সচিব মো. আব্দুর রহিম বলেন, পবিত্র রমজান মাস এলেই ব্যবসায়ীদের মধ্যে বেশি মুনাফা করার প্রবণতা তৈরি হয়। \nExtracted Names: ['মো. আব্দুর রহিম']\nGiven Text: শিক্ষা মন্ত্রণালয়ের দায়িত্বশীল একটি সূত্রে জানা যায়, মুহাম্মদ আজাদ খানের বিষয়ে শিক্ষা মন্ত্রণালয়ের নীতিনির্ধারকেরা সন্তুষ্ট ছিলেন না। \nExtracted Names: ['মুহাম্মদ আজাদ খানের']\n","output_type":"stream"}],"execution_count":47}]}